# Web Search Skill

**ç½‘ç»œæœç´¢æŠ€èƒ½** - ä¸ºResearch Agentæä¾›ç½‘ç»œæœç´¢å’Œä¿¡æ¯æ”¶é›†èƒ½åŠ›

---

## ğŸ¯ æŠ€èƒ½æ¦‚è¿°

è¿™ä¸ªæŠ€èƒ½ä¸ºLeo AI Agent Systemæä¾›ç½‘ç»œæœç´¢èƒ½åŠ›ï¼Œæ”¯æŒï¼š
- å…³é”®è¯æœç´¢
- ç½‘é¡µå†…å®¹æŠ“å–
- ä¿¡æ¯æå–å’Œæ‘˜è¦
- å¤šæ¥æºæ•´åˆ

## ğŸ“‹ åŠŸèƒ½åˆ—è¡¨

### 1. æœç´¢åŠŸèƒ½
- å…³é”®è¯æœç´¢
- é«˜çº§æœç´¢ï¼ˆæ—¶é—´èŒƒå›´ã€ç½‘ç«™é™å®šç­‰ï¼‰
- æœç´¢ç»“æœæ’åºå’Œè¿‡æ»¤

### 2. å†…å®¹æŠ“å–
- ç½‘é¡µHTMLæŠ“å–
- æ–‡æœ¬å†…å®¹æå–
- ç»“æ„åŒ–æ•°æ®æå–

### 3. ä¿¡æ¯å¤„ç†
- å†…å®¹æ‘˜è¦ç”Ÿæˆ
- å…³é”®ä¿¡æ¯æå–
- å¤šæ¥æºä¿¡æ¯æ•´åˆ

## ğŸ”§ ä½¿ç”¨æ–¹å¼

### åŸºç¡€æœç´¢
```python
from web_search_skill import WebSearchSkill

skill = WebSearchSkill()
results = skill.search(query="äººå·¥æ™ºèƒ½å‘å±•è¶‹åŠ¿", max_results=10)
```

### å†…å®¹æŠ“å–
```python
content = skill.fetch_content(url="https://example.com")
```

### ä¿¡æ¯æå–
```python
summary = skill.extract_info(content, keywords=["AI", "æœºå™¨å­¦ä¹ "])
```

## ğŸ“Š é…ç½®é€‰é¡¹

```yaml
web_search:
  search_engine: "google"  # google, bing, duckduckgo
  max_results: 10
  timeout: 30
  user_agent: "Mozilla/5.0..."
  language: "zh-CN"
```

## ğŸ”Œ é›†æˆæ–¹å¼

### ä¸Research Agenté›†æˆ
```python
class ResearchAgent(BaseAgent):
    def execute(self, task, **kwargs):
        # ä½¿ç”¨WebSearch Skill
        results = self.use_skill("web-search-cskill", "search", query=task)
        return results
```

## ğŸ“ APIè¯´æ˜

### search(query, max_results=10, **kwargs)
æ‰§è¡Œç½‘ç»œæœç´¢

**å‚æ•°**:
- `query` (str): æœç´¢å…³é”®è¯
- `max_results` (int): æœ€å¤§ç»“æœæ•°
- `time_range` (str): æ—¶é—´èŒƒå›´ï¼ˆå¯é€‰ï¼‰
- `site` (str): é™å®šç½‘ç«™ï¼ˆå¯é€‰ï¼‰

**è¿”å›**:
```python
{
    "query": "æœç´¢å…³é”®è¯",
    "results": [
        {
            "title": "æ ‡é¢˜",
            "url": "é“¾æ¥",
            "snippet": "æ‘˜è¦",
            "source": "æ¥æº"
        }
    ],
    "total": 10
}
```

### fetch_content(url, **kwargs)
æŠ“å–ç½‘é¡µå†…å®¹

**å‚æ•°**:
- `url` (str): ç½‘é¡µURL
- `timeout` (int): è¶…æ—¶æ—¶é—´

**è¿”å›**:
```python
{
    "url": "ç½‘é¡µURL",
    "title": "é¡µé¢æ ‡é¢˜",
    "content": "æ–‡æœ¬å†…å®¹",
    "html": "HTMLå†…å®¹",
    "metadata": {...}
}
```

### extract_info(content, keywords=None, **kwargs)
æå–å…³é”®ä¿¡æ¯

**å‚æ•°**:
- `content` (str): æ–‡æœ¬å†…å®¹
- `keywords` (list): å…³é”®è¯åˆ—è¡¨

**è¿”å›**:
```python
{
    "summary": "å†…å®¹æ‘˜è¦",
    "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
    "entities": ["å®ä½“1", "å®ä½“2"],
    "facts": ["äº‹å®1", "äº‹å®2"]
}
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæˆ¿åœ°äº§æ”¿ç­–æœç´¢
```python
# æœç´¢æœ€æ–°æˆ¿åœ°äº§æ”¿ç­–
results = skill.search(
    query="å®æ³¢æˆ¿åœ°äº§æ”¿ç­– 2026",
    time_range="past_month",
    max_results=20
)

# æŠ“å–è¯¦ç»†å†…å®¹
for result in results["results"]:
    content = skill.fetch_content(result["url"])
    info = skill.extract_info(content, keywords=["æ”¿ç­–", "è°ƒæ§", "é™è´­"])
```

### ç¤ºä¾‹2ï¼šå¸‚åœºè°ƒç ”
```python
# æœç´¢AIçœ¼é•œå¸‚åœºä¿¡æ¯
results = skill.search(
    query="AIçœ¼é•œå¸‚åœºè§„æ¨¡ è¶‹åŠ¿",
    max_results=15
)

# æ•´åˆä¿¡æ¯
all_info = []
for result in results["results"]:
    content = skill.fetch_content(result["url"])
    info = skill.extract_info(content)
    all_info.append(info)
```

## ğŸ”’ æ³¨æ„äº‹é¡¹

1. **APIé™åˆ¶**: æŸäº›æœç´¢å¼•æ“æœ‰APIè°ƒç”¨é™åˆ¶
2. **ç½‘ç«™robots.txt**: éµå®ˆç½‘ç«™çš„çˆ¬è™«è§„åˆ™
3. **è¯·æ±‚é¢‘ç‡**: é¿å…è¿‡äºé¢‘ç¹çš„è¯·æ±‚
4. **å†…å®¹ç‰ˆæƒ**: æ³¨æ„å†…å®¹ä½¿ç”¨çš„ç‰ˆæƒé—®é¢˜

## ğŸš€ æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒæ›´å¤šæœç´¢å¼•æ“
- [ ] æ·»åŠ å›¾ç‰‡æœç´¢
- [ ] æ”¯æŒPDFæ–‡æ¡£æŠ“å–
- [ ] æ·»åŠ ç¼“å­˜æœºåˆ¶
- [ ] å®ç°æ™ºèƒ½å»é‡

---

**åˆ›å»ºæ—¶é—´**: 2026-01-09
**ç»´æŠ¤è€…**: Leo Liu
**ç‰ˆæœ¬**: 1.0.0
